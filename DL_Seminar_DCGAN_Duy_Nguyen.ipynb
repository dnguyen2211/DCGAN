{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Seminar_DCGAN_Duy_Nguyen.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "SfMilt-AYM5d",
        "cq7OaFB2ZzBn"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyXKMTjfZPUh",
        "colab_type": "text"
      },
      "source": [
        "# Hochschule Offenburg - Seminar Deep Learning\n",
        "## Deep Convolutional Generative Adversarial Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zivxJ0egWSrN",
        "colab_type": "text"
      },
      "source": [
        "This notebook will give you a introduction about the implementation and needed steps of the DCGAN architecture.\n",
        "For the demonstration this notebook used the MNIST dataset to generate handwriten digits.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "229QDr9vZH_8",
        "colab_type": "text"
      },
      "source": [
        "________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkuX2UJmQSIx",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Deep Convolution Generative Adversarial Network or DCGAN is a advanced solution of GAN. \n",
        "The base concept of DCGAN is the same as GAN.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4n_lMy0WYUk",
        "colab_type": "text"
      },
      "source": [
        "**What is GAN?**\n",
        "\n",
        "In GAN there are two networks trained simultaneously against each other, the generator learns to create real images, while the discriminator learns to classify real and fake images. The goal is archieved when the discriminator can't no longer distinguish real from fake images.\n",
        "\n",
        "\n",
        "The following gif shows generated handwritten digits, created by the generator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQeTjzFoWcCE",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://www.tensorflow.org/images/gan/dcgan.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFT01bEmsMkh",
        "colab_type": "text"
      },
      "source": [
        "**What is DCGAN?**\n",
        "\n",
        "As the name indicates, the concept of DCGAN is the same as GAN except for the number of layers. Instead of using a few convolution layers to generate and classify images, DCGAN have multiple covolution layers. With sufficent layers you can call it deep convolution. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HPVY-1oW70c",
        "colab_type": "text"
      },
      "source": [
        "For more information about\n",
        "\n",
        "DCGAN:\n",
        "\n",
        "*   https://arxiv.org/pdf/1511.06434.pdf\n",
        "\n",
        "GAN:\n",
        "\n",
        "*   https://arxiv.org/pdf/1710.07035.pdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D72nRJxuWu_T",
        "colab_type": "text"
      },
      "source": [
        "________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfMilt-AYM5d",
        "colab_type": "text"
      },
      "source": [
        "## Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PCU3ybvdWiz",
        "colab_type": "text"
      },
      "source": [
        "Before we can start with the implementation, we have to install some packages and import libraries.\n",
        "\n",
        "The code below doing this for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK8ErkAECBNj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf5734f5-b0c4-4b0d-a730-06715508f232"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr-Z1KxH8Um9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk7RN5JV74s_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "857d30a1-fddc-49da-f20a-d4f713f571ee"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from keras.utils.vis_utils import plot_model\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeDozWqbCv_C",
        "colab_type": "code",
        "outputId": "09bb16cf-913a-4025-d714-f6274badbe6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# To generate GIFs\n",
        "!pip install imageio\n",
        "\n",
        "!pip install -q pydot\n",
        "!pip install -q graphviz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.1.0/python3.6 (from imageio) (1.18.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (6.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJIqWDKE3A_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRh9kSD0aHDX",
        "colab_type": "text"
      },
      "source": [
        "## Load and prepare dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PiXU4_BeIw9",
        "colab_type": "text"
      },
      "source": [
        "As already mentioned, we use the MNIST dataset to train the models.\n",
        "\n",
        "On this point we do not need to load the dataset from Google Drive or other locations. Keras already offers the MNIST and also other datasets.\n",
        "\n",
        "Link to the datasets: https://www.tensorflow.org/api_docs/python/tf/keras/datasets\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXT4k6wfgNaM",
        "colab_type": "text"
      },
      "source": [
        "_______________________________________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK1dcKxngP1G",
        "colab_type": "text"
      },
      "source": [
        "The following code loads and prepare the dataset for the training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1J4iL-wCQJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets.mnist import load_data\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = load_data()\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfgC_HoOax4E",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVz3g8LViFU-",
        "colab_type": "text"
      },
      "source": [
        "The following hyperparameters are used and adjust to train both Networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZEOGdbgCSem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "EPOCHS = 20\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "leakyReLU = 0.2\n",
        "\n",
        "dropout = 0.3\n",
        "\n",
        "l_rate = 0.0002\n",
        "beta = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zh235mroaMdF",
        "colab_type": "text"
      },
      "source": [
        "## Define and create Generator and Discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENKh4E6likRI",
        "colab_type": "text"
      },
      "source": [
        "In this section the generator and descriminator will be defined. \n",
        "\n",
        "Remember, the models parameterisation should only be used for the MNIST dataset. If you want to train the models with other datasets like CIFAR10, CIFAR100 etc. you have to adjust the parameters. It is also advisable to add more layers or replace some layers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2QR_VA0phRz",
        "colab_type": "text"
      },
      "source": [
        "Architecture guidelines for stable Deep Convolutional GANs\n",
        "\n",
        "*   Replace any pooling layers with strided convolutions (discriminator) and fractional-strided\n",
        "convolutions (generator).\n",
        "*   Use batchnorm in both the generator and the discriminator.\n",
        "*   Remove fully connected hidden layers for deeper architectures.\n",
        "*   Use ReLU activation in generator for all layers except for the output, which uses Tanh.\n",
        "*   Use LeakyReLU activation in the discriminator for all layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utwa7JxPbWzJ",
        "colab_type": "text"
      },
      "source": [
        "### Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz_rkktKjzGe",
        "colab_type": "text"
      },
      "source": [
        "The generator uses Transposed layer to produce a image from the previous layer. Start with a Dense layer that takes the seed input and produce a 28x28x1 image for the next layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fypfiRSnCUt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(leakyReLU))\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(leakyReLU))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(leakyReLU))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czx0Cb-8CawI",
        "colab_type": "code",
        "outputId": "0b1019e6-d057-4508-c127-e03aeb364911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "#generator model\n",
        "generator = make_generator_model()\n",
        "\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f82ba1f4358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7EJkgswuRCbI7EJkgswuRCbI7EJkwv8ClaSaHJapV7sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgNVq-b6bbea",
        "colab_type": "text"
      },
      "source": [
        "### Discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7ZD9Qb2ksPB",
        "colab_type": "text"
      },
      "source": [
        "The discriminator is a based CNN classifier, use convolution layers to downsample the input image. At the end the output will be a positiv value for real images and negative value for fake images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URavCZmYCZJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential(name=\"Discriminator\")\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU(leakyReLU))\n",
        "    model.add(layers.Dropout(dropout))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU(leakyReLU))\n",
        "    model.add(layers.Dropout(dropout))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L87CKXsJH3Zf",
        "colab_type": "code",
        "outputId": "62b52c58-3cb7-4de6-8111-178036558284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "#discriminator model\n",
        "discriminator = make_discriminator_model()\n",
        "discriminator.summary()\n",
        "\n",
        "decision = discriminator(generated_image)\n",
        "print (decision)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 14, 14, 64)        1664      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 7, 7, 128)         204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 6273      \n",
            "=================================================================\n",
            "Total params: 212,865\n",
            "Trainable params: 212,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "tf.Tensor([[0.00159213]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zZxI6cBaw-5",
        "colab_type": "text"
      },
      "source": [
        "## Define loss and optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yOTUdUNxyoW",
        "colab_type": "text"
      },
      "source": [
        "In this section we will define the loss function and optimizer for both models.\n",
        "\n",
        "Binary cross entropy is used to compute the loss and the adam optimizer for the optimization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBAyWV85CcLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0UXJrs2x92f",
        "colab_type": "text"
      },
      "source": [
        "**Discriminator loss**\n",
        "\n",
        "\"*This method quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s.*\" \n",
        "\n",
        "[ https://www.tensorflow.org/tutorials/generative/dcgan ]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T2upomuCdkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOVf9BbHy0j6",
        "colab_type": "text"
      },
      "source": [
        "**Generator loss**\n",
        "\n",
        "\"*The generator's loss quantifies how well it was able to trick the discriminator. Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1). Here, we will compare the discriminators decisions on the generated images to an array of 1s.*\"\n",
        "\n",
        "[ https://www.tensorflow.org/tutorials/generative/dcgan ] "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1XPOrt1CfQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUZq40SB7LiK",
        "colab_type": "text"
      },
      "source": [
        "**Optimizer**\n",
        "\n",
        "The optimizer compute the gradient to udpate the generator and discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86SKNaDfCgL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate = l_rate, beta_1=beta)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate = l_rate, beta_1=beta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p02n9zNKZvbY",
        "colab_type": "text"
      },
      "source": [
        "## Training Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUM6wndrwhUE",
        "colab_type": "text"
      },
      "source": [
        "### Generate and save Image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9E9CbTX5hKB",
        "colab_type": "text"
      },
      "source": [
        "This code generate and save an image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tIa4DIfC54o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save path for the generated image\n",
        "image_path = ''\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig(image_path + 'image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC8TtZvowyib",
        "colab_type": "text"
      },
      "source": [
        "### Generate loss function diagram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9AEWRv85Mro",
        "colab_type": "text"
      },
      "source": [
        "This code generate a loss diagram of both models, using the losses during the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOO21ctjabkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_train_hist(hist, show = False, save = False, path = 'Train_hist.png'):\n",
        "    x = range(len(hist['D_losses']))\n",
        "\n",
        "    y1 = np.array(hist['D_losses'])\n",
        "    y2 = np.array(hist['G_losses'])\n",
        "\n",
        "    plt.plot(x, y1, label='D_loss')\n",
        "    plt.plot(x, y2, label='G_loss')\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    plt.legend(loc=4)\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save:\n",
        "        plt.savefig(path)\n",
        "\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qAApuQ4w82C",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGDMowog5pV4",
        "colab_type": "text"
      },
      "source": [
        "\"*The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator.*\"\n",
        "\n",
        "[ https://www.tensorflow.org/tutorials/generative/dcgan ]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RhWpXogCznT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_hist = {}\n",
        "train_hist['D_losses'] = []\n",
        "train_hist['G_losses'] = []\n",
        "\n",
        "# We will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzGNzKGsC38P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    G_losses = []\n",
        "    D_losses = []\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "      with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(image_batch, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "      gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "      gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "      generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "      discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "      D_losses.append(disc_loss)\n",
        "      G_losses.append(gen_loss)\n",
        "      \n",
        "\n",
        "\n",
        "    # Produce images for the GIF as we go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator, epoch + 1, seed)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "    train_hist['D_losses'].append(np.mean(D_losses))\n",
        "    train_hist['G_losses'].append(np.mean(G_losses))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator, epochs, seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymSHKDRmC7H0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#start the training\n",
        "\n",
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "train(train_dataset, EPOCHS)\n",
        "\n",
        "show_train_hist(train_hist, save=True, path='train_hist.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2d-cpcOv-Tz",
        "colab_type": "text"
      },
      "source": [
        "### Util"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfukLtAiC9bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display a single image using the epoch number\n",
        "def display_image(epoch_no):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1uLKAsu6Gaq",
        "colab_type": "text"
      },
      "source": [
        "The following code create an animated image, using the images during the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pAaGfQzC_wY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_gif():\n",
        "    anim_file = 'dcgan.gif'\n",
        "\n",
        "    with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "      filenames = glob.glob('image*.png')\n",
        "      filenames = sorted(filenames)\n",
        "      last = -1\n",
        "      for i,filename in enumerate(filenames):\n",
        "        frame = 2*(i**0.5)\n",
        "        if round(frame) > round(last):\n",
        "          last = frame\n",
        "        else:\n",
        "          continue\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "      image = imageio.imread(filename)\n",
        "      writer.append_data(image)\n",
        "\n",
        "    import IPython\n",
        "    if IPython.version_info > (6,2,0,''):\n",
        "      display.Image(filename=anim_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq7OaFB2ZzBn",
        "colab_type": "text"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5DXJkPecguF",
        "colab_type": "text"
      },
      "source": [
        "To mount your drive, use the following code\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSQMRHQ_HM5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}